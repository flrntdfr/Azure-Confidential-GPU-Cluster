{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d75d0ce",
   "metadata": {},
   "source": [
    "<!-- du4://thèse/cai/results.ipynb?d=20251024?loc=ttum?hPa=1020 -->\n",
    "\n",
    "# Confidential Artificial Intelligence: What's the Catch?\n",
    "### _Performance and costs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from functools import cached_property\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5474bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\", context=\"paper\")\n",
    "sns.set_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b8e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent folder containing the data\n",
    "data_path = Path(\"data\", \"ko\")  # ← FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Experiment:\n",
    "    path: Path\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self.path.stem\n",
    "\n",
    "    @cached_property\n",
    "    def conditions(self) -> List[\"Condition\"]:\n",
    "        return [\n",
    "            Condition(q, q.parent.name, q.name == \"tee_on\")\n",
    "            for q in self.path.glob(\"*/*\")\n",
    "            if q.is_dir() and q.name in {\"tee_on\", \"tee_off\"}\n",
    "        ]\n",
    "\n",
    "    def get_all_conditions(self):\n",
    "        return self.conditions\n",
    "\n",
    "    def get_all_conditions_names(self, sort_by_model_size: bool=False):\n",
    "        all_conditions = self.conditions\n",
    "        if sort_by_model_size:\n",
    "            all_conditions_sorted = sorted(all_conditions, key=lambda c: int(c.model_size))\n",
    "            return list(dict.fromkeys(c.name for c in all_conditions_sorted))\n",
    "        else:\n",
    "            return list(dict.fromkeys(c.name for c in all_conditions))\n",
    "\n",
    "    def get_conditions(self, tee_on: bool=False):\n",
    "        return [c for c in self.conditions if c.tee_on == tee_on]\n",
    "\n",
    "    def get_condition(self, name: str, tee_on: bool=False):\n",
    "        return next(\n",
    "            filter(lambda c: c.name == name and c.tee_on == tee_on, self.conditions),\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Experiment: {self.name}, Path: {self.path.absolute()}, {len(self.conditions)} conditions: {[c.name for c in self.conditions]}\"\n",
    "\n",
    "@dataclass\n",
    "class Condition:\n",
    "    path: Path\n",
    "    name: str\n",
    "    tee_on: bool\n",
    "\n",
    "    @property\n",
    "    def model_name(self) :\n",
    "        return self.path.parent.name.split(\"_\")\n",
    "\n",
    "    @property\n",
    "    def model_size(self) -> str:\n",
    "        return re.search(r\"(\\d+)[bB]\", \"_\".join(self.model_name)).group(1)\n",
    "\n",
    "    @cached_property\n",
    "    def repetitions(self) -> List[\"Repetition\"]:\n",
    "        repetitions_paths = list(self.path.glob(\"*repetition_*\"))\n",
    "        json_files = sorted([r for r in repetitions_paths if r.suffix == \".json\"])\n",
    "        csv_files = sorted([r for r in repetitions_paths if r.suffix == \".csv\"])\n",
    "\n",
    "        assert len(list(repetitions_paths)) > 0, \"Empty results\"\n",
    "        assert len(json_files) == len(csv_files), f\"Mismatch: {len(json_files)} .json vs. {len(csv_files)} .csv\"\n",
    "\n",
    "        return [\n",
    "            Repetition(\n",
    "                idx, json_file, self.path / f\"{json_file.stem}_power_metrics.csv\"\n",
    "            )\n",
    "            for idx, json_file in enumerate(json_files)\n",
    "        ]\n",
    "\n",
    "    def get_all_repetitions(self) -> List[\"Repetition\"]:\n",
    "        return self.repetitions\n",
    "\n",
    "    def get_repetition(self, tee_on: bool, index: int) -> \"Repetition\":\n",
    "        return self.repetitions[index]\n",
    "\n",
    "    def get_median_throughput_with_std(self) -> Tuple[float, float]:\n",
    "        output_throughputs = [\n",
    "            rep.get_vllm_key(\"output_throughput\") for rep in self.repetitions\n",
    "        ]\n",
    "        return np.median(output_throughputs), np.std(output_throughputs)\n",
    "\n",
    "@dataclass\n",
    "class Repetition:\n",
    "    index: int\n",
    "    path_vllm_json: Path\n",
    "    path_power_csv: Path\n",
    "\n",
    "    @cached_property\n",
    "    def vllm_results(self) -> dict:\n",
    "        return json.loads(self.path_vllm_json.read_text())\n",
    "\n",
    "    @cached_property\n",
    "    def power_results(self) -> pd.DataFrame:\n",
    "        return pd.read_csv(self.path_power_csv)\n",
    "\n",
    "    @property\n",
    "    def dataset(self) -> str:\n",
    "        return self.vllm_results[\"dataset\"]\n",
    "\n",
    "    @property\n",
    "    def model_id(self) -> str:\n",
    "        return self.vllm_results[\"model\"]\n",
    "\n",
    "    @property\n",
    "    def input_length(self) -> int:\n",
    "        return self.vllm_results[\"input_length\"]\n",
    "\n",
    "    @property\n",
    "    def output_length(self) -> int:\n",
    "        return self.vllm_results[\"output_length\"]\n",
    "\n",
    "    @property\n",
    "    def concurrency(self) -> int:\n",
    "        return self.vllm_results[\"concurrency\"]\n",
    "\n",
    "    @property\n",
    "    def temperature(self) -> float:\n",
    "        return self.vllm_results[\"temperature\"]\n",
    "\n",
    "    def get_vllm_key(self, key: str):\n",
    "        return self.vllm_results[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295f99c",
   "metadata": {},
   "source": [
    "# 0. Data summary\n",
    "\n",
    "- Number of run\n",
    "- Total accumulated time (+ estimated cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93012090",
   "metadata": {},
   "source": [
    "## 1. Throughput and Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c04414",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_throughput_latency = Experiment(data_path.joinpath(\"throughput_latency\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56732dbe",
   "metadata": {},
   "source": [
    "## Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251133ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []  # We build row by row\n",
    "for condition in experiment_throughput_latency.get_all_conditions():\n",
    "    repetitions_paths = condition.get_all_repetitions()\n",
    "\n",
    "    for rep in repetitions_paths:\n",
    "        assert all(e == \"\" for e in rep.get_vllm_key(\"errors\")), (\n",
    "            \"vLLM reported an error. Check .json.\"\n",
    "        )\n",
    "        rows.append(\n",
    "            {\n",
    "                # Repetition\n",
    "                \"condition\": condition.name,\n",
    "                \"tee_on\": condition.tee_on,\n",
    "                \"repetition #\": rep.index,\n",
    "                \"duration (s)\": round(rep.get_vllm_key(\"duration\")),\n",
    "                # Throughput\n",
    "                \"output throughput (tok/s)\": rep.get_vllm_key(\"output_throughput\"),\n",
    "                \"total token throughput (tok/s)\": rep.get_vllm_key(\n",
    "                    \"total_token_throughput\"\n",
    "                ),\n",
    "                # Latency\n",
    "                \"Azure cost (€)\": round(rep.get_vllm_key(\"duration\") / 3600 * 7, 3),\n",
    "            }\n",
    "        )\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8393a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for condition in experiment_throughput_latency.get_all_conditions_names(sort_by_model_size=True):\n",
    "    print(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f091c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_labels = []\n",
    "tee_on_medians, tee_on_stds = [], []\n",
    "tee_off_medians, tee_off_stds = [], []\n",
    "\n",
    "for condition in experiment_throughput_latency.get_all_conditions_names(sort_by_model_size=True):\n",
    "    condition_labels.append(condition)\n",
    "    median_tee_on, std_tee_on = experiment_throughput_latency.get_condition(\n",
    "        condition, True\n",
    "    ).get_median_throughput_with_std()\n",
    "    tee_on_medians.append(median_tee_on)\n",
    "    tee_on_stds.append(std_tee_on)\n",
    "    median_tee_off, std_tee_off = experiment_throughput_latency.get_condition(\n",
    "        condition, False\n",
    "    ).get_median_throughput_with_std()\n",
    "    tee_off_medians.append(median_tee_off)\n",
    "    tee_off_stds.append(std_tee_off)\n",
    "\n",
    "# Plot grouped bar chart with error bars\n",
    "x = np.arange(len(condition_labels))\n",
    "width = 0.20  # Width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(\n",
    "    x - width / 2,\n",
    "    tee_on_medians,\n",
    "    width,\n",
    "    yerr=tee_on_stds,\n",
    "    label=\"TEE On\",\n",
    "    capsize=5,\n",
    "    alpha=0.8,\n",
    ")\n",
    "bars2 = ax.bar(\n",
    "    x + width / 2,\n",
    "    tee_off_medians,\n",
    "    width,\n",
    "    yerr=tee_off_stds,\n",
    "    label=\"TEE Off\",\n",
    "    capsize=5,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "# Add labels, title and legend\n",
    "ax.set_xlabel(\"Conditions\")\n",
    "ax.set_ylabel(\"Throughput\")\n",
    "ax.set_title(\"Throughput Comparison: TEE On vs TEE Off\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(condition_labels, rotation=45, ha=\"right\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a0b05a",
   "metadata": {},
   "source": [
    "## 2. Saturation point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vllm_data.get(\"max_concurrent_requests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ef0d4",
   "metadata": {},
   "source": [
    "## 3. Sequence length overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a576b95",
   "metadata": {},
   "source": [
    "## 5. Energy efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f155368",
   "metadata": {},
   "source": [
    "## 4. Price of operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530add0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
